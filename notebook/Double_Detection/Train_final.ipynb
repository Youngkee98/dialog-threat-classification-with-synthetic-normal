{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16235,"status":"ok","timestamp":1746579521243,"user":{"displayName":"권재현","userId":"02074875056020008335"},"user_tz":-540},"id":"YbaoEpCkQrPC","outputId":"3dd8dac2-cd2d-4c34-d889-1632b136b869"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":631,"referenced_widgets":["8d65395de6af46e5a9b7d3765e0e91e2","497420167f6d4692ba5ebfb1d524ee25","a26d0e5adf484a3ea35e3c28962927eb","d40a39d1c6f54605bbb7f87f3ba065df","a5bd63d2f10f474f93d865ff21f504fa","7aa763b733c3466bb9b832b3f8f146eb","517ab2449e2e432fb101a8612a00c7a0","3b307d8865e44523b7d712411a14e815","6fd7613618b54891b26edfa003c0c7f0","b7c3cd1bc81946e4bbf32117ed1d9f33","1e44693b5e3b453a9f53f4fe1bc7bc01","65ee54b369184f36a2380c603ee35f52","9f9f8aa278cf45879a618749794a5467","5de847639cdd4ae7b361c4b3ab073ce7","e2bcda98bb784ae28601f1018bd920d3","5e6e1bd4fa284c659be9233c98c91faa","1ecec955dbf04f748cad137bd04bb6d2","6d9102f641464f71a740cfbe0cfc410b","1828e7a57bf44835a850ebf2fe7117bb","b5ce87fdcc4b407191dc77b3f4104c5f","a2a7eb3e33b54187b005f56627b3da9e","6d288cd22c094ad9b11a8d6fcd645107","4d6a039c545e44558445f71e4339e875","694a0f8a6e814d43be4ae889fdc85d7c","72891edb5a054d45a82141fce11b8c65","54d692adf84346a1a5863167d82cb010","552e8c9d0fec497387012ee2850ee061","f9a8103a555742b3a4577ccd231c92df","971fc55f0eae45e39a974b9c8cadf986","173b5f13a2364c6281e6759bec25c603","68fe0ff4692346bd911d7cfbc5dafc7f","3211ad0b8ca84cc08764eece9771cc41","296babf6668349b3b5068dd276775973","4c0c3da9dd1141b88a2049b6a033e4c5","bf8288481891438eaf38cf5597a6b77f","c226ef96648449a7b5d284802725486f","79eedd85521247db860dba8bea6377a1","34f51280f2f24292a1ad790e009cc8e7","6c3c7c706bef4bdbb3863e55be8548e0","41592c67b28340dfbe4a55c0c55e510b","45dc06139bc449a5947a20ade7d60a35","f4fd15a00fef4010b031f41f24e822a4","05419867b0144b248f41a87e87fb5784","464154207f904b02a917105f07303101"]},"executionInfo":{"elapsed":1029254,"status":"ok","timestamp":1746348035464,"user":{"displayName":"권재현","userId":"02074875056020008335"},"user_tz":-540},"id":"4BJR4i_2PAO-","outputId":"c428faab-b710-4aa5-afa9-6494904bbea2"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8d65395de6af46e5a9b7d3765e0e91e2","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"65ee54b369184f36a2380c603ee35f52","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/250k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4d6a039c545e44558445f71e4339e875","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/619 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4c0c3da9dd1141b88a2049b6a033e4c5","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[Binary Epoch 1] Loss: 0.5293\n","[Binary Epoch 2] Loss: 0.4392\n","[Binary Epoch 3] Loss: 0.3802\n","[Binary Epoch 4] Loss: 0.3318\n","[Binary Epoch 5] Loss: 0.2916\n","[Binary Epoch 6] Loss: 0.2580\n","[Binary Epoch 7] Loss: 0.2297\n","[Binary Epoch 8] Loss: 0.2055\n","[Binary Epoch 9] Loss: 0.1847\n","[Binary Epoch 10] Loss: 0.1667\n","[Binary Epoch 11] Loss: 0.1511\n","[Binary Epoch 12] Loss: 0.1374\n","[Binary Epoch 13] Loss: 0.1254\n","[Binary Epoch 14] Loss: 0.1147\n","[Binary Epoch 15] Loss: 0.1053\n","[Binary Epoch 16] Loss: 0.0968\n","[Binary Epoch 17] Loss: 0.0891\n","[Binary Epoch 18] Loss: 0.0823\n","[Binary Epoch 19] Loss: 0.0762\n","[Binary Epoch 20] Loss: 0.0707\n","✅ 다중 분류 대상으로 넘어갈 샘플 수: 3851\n","❗ 잘못 1로 분류된 일반대화 샘플 수: 0\n"]}],"source":["# Binary_Train\n","\n","import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizer, BertModel\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import random\n","\n","# 전처리 및 로딩\n","label_map = {\n","    '일반대화': 0,\n","    '협박 대화': 1,\n","    '갈취 대화': 2,\n","    '직장 내 괴롭힘 대화': 3,\n","    '기타 괴롭힘 대화': 4\n","}\n","\n","csv_path = '/content/drive/MyDrive/DLthon/merged_dataset_2.csv'\n","raw_df = pd.read_csv(csv_path)\n","raw_df['label'] = raw_df['class'].map(label_map)\n","raw_df.rename(columns={'class': 'original_label', 'conversation': 'text'}, inplace=True)\n","\n","# 모델 및 데이터셋 정의\n","\n","tokenizer = BertTokenizer.from_pretrained(\"beomi/kcbert-base\")\n","\n","class SharedBERT(nn.Module):\n","    def __init__(self, model_name=\"beomi/kcbert-base\"):\n","        super().__init__()\n","        self.bert = BertModel.from_pretrained(model_name)\n","        for p in self.bert.parameters():\n","            p.requires_grad = False\n","\n","    def forward(self, input_ids, attention_mask):\n","        return self.bert(input_ids=input_ids, attention_mask=attention_mask).pooler_output\n","\n","class BinaryClassifier(nn.Module):\n","    def __init__(self, hidden_size=768):\n","        super().__init__()\n","        self.classifier = nn.Linear(hidden_size, 2)\n","\n","    def forward(self, cls_output):\n","        return self.classifier(cls_output)\n","\n","class BinaryClassificationDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_length=128):\n","        self.texts = dataframe['text'].tolist()\n","        self.labels = dataframe['label'].tolist()\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","        self.binary_labels = [0 if label == 0 else 1 for label in self.labels]\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        encoding = self.tokenizer(\n","            self.texts[idx],\n","            truncation=True,\n","            padding='max_length',\n","            max_length=self.max_length,\n","            return_tensors='pt'\n","        )\n","        item = {key: val.squeeze(0) for key, val in encoding.items()}\n","        item['label'] = torch.tensor(self.binary_labels[idx], dtype=torch.long)\n","        item['original_label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n","        return item\n","\n","def train_model(model, dataloader, optimizer, device):\n","    model.train()\n","    total_loss = 0\n","    for batch in dataloader:\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['label'].to(device)\n","\n","        optimizer.zero_grad()\n","        cls_output = shared_bert(input_ids, attention_mask)\n","        logits = model(cls_output)\n","        loss = F.cross_entropy(logits, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","    return total_loss / len(dataloader)\n","\n","# 실행\n","shared_bert = SharedBERT().to(\"cuda\")\n","binary_dataset = BinaryClassificationDataset(raw_df, tokenizer)\n","binary_loader = DataLoader(binary_dataset, batch_size=32, shuffle=True)\n","binary_head = BinaryClassifier().to(\"cuda\")\n","optimizer_bin = torch.optim.Adam(binary_head.parameters(), lr=2e-5)\n","\n","for epoch in range(20):\n","    loss = train_model(binary_head, binary_loader, optimizer_bin, \"cuda\")\n","    print(f\"[Binary Epoch {epoch+1}] Loss: {loss:.4f}\")\n","\n","torch.save(binary_head.state_dict(), \"/content/drive/MyDrive/DLthon/binary_4.pt\")\n","\n","# 결과 추출만 (파일 저장 제거)\n","binary_head.eval()\n","selected_indices = []\n","incorrect_zero_indices = []\n","\n","with torch.no_grad():\n","    for batch_idx, batch in enumerate(binary_loader):\n","        input_ids = batch['input_ids'].to(\"cuda\")\n","        attention_mask = batch['attention_mask'].to(\"cuda\")\n","        original_labels = batch['original_label']\n","\n","        cls_output = shared_bert(input_ids, attention_mask)\n","        logits = binary_head(cls_output)\n","        preds = torch.argmax(logits, dim=1)\n","\n","        for i, pred in enumerate(preds):\n","            global_idx = batch_idx * binary_loader.batch_size + i\n","            true_label = original_labels[i].item()\n","            if pred.item() == 1 and true_label != 0:\n","                selected_indices.append(global_idx)\n","            elif pred.item() == 1 and true_label == 0:\n","                incorrect_zero_indices.append(global_idx)\n","\n","print(f\"다중 분류 대상으로 넘어갈 샘플 수: {len(selected_indices)}\")\n","print(f\"잘못 1로 분류된 일반대화 샘플 수: {len(incorrect_zero_indices)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WBZdFI29V348"},"outputs":[],"source":["# Multi\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizer, BertModel\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from sklearn.metrics import classification_report\n","import pandas as pd\n","\n","class MultiClassificationDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_length=64):\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","        # 일반대화 1000개 + 괴롭힘 전체 구성\n","        df_0 = dataframe[dataframe['label'] == 0].sample(n=2000, random_state=42)\n","        df_1to4 = dataframe[dataframe['label'].isin([1, 2, 3, 4])]\n","        balanced_df = pd.concat([df_0, df_1to4], ignore_index=True)\n","\n","        self.selected_texts = balanced_df['text'].tolist()\n","        self.selected_labels = balanced_df['label'].tolist()\n","\n","    def __len__(self):\n","        return len(self.selected_texts)\n","\n","    def __getitem__(self, idx):\n","        encoding = self.tokenizer(\n","            self.selected_texts[idx],\n","            truncation=True,\n","            padding='max_length',\n","            max_length=self.max_length,\n","            return_tensors='pt'\n","        )\n","        item = {key: val.squeeze(0) for key, val in encoding.items()}\n","        item['label'] = torch.tensor(self.selected_labels[idx], dtype=torch.long)\n","        return item\n","\n","class MultiClassifier(nn.Module):\n","    def __init__(self, hidden_size=768, num_classes=5):\n","        super().__init__()\n","        self.classifier = nn.Sequential(\n","            nn.Linear(hidden_size, 512),\n","            nn.ReLU(),\n","            nn.BatchNorm1d(512),\n","            nn.Linear(512, 256),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(256, num_classes)\n","        )\n","\n","    def forward(self, cls_output):\n","        return self.classifier(cls_output)\n","\n","# 학습 및 평가 코드\n","\n","def train_and_evaluate(dataframe, tokenizer, shared_bert):\n","    dataset = MultiClassificationDataset(dataframe, tokenizer)\n","    loader = DataLoader(dataset, batch_size=32, shuffle=True)\n","\n","    model = MultiClassifier().to(\"cuda\")\n","    optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n","\n","    for epoch in range(50):\n","        model.train()\n","        total_loss = 0\n","        for batch in loader:\n","            input_ids = batch['input_ids'].to(\"cuda\")\n","            attention_mask = batch['attention_mask'].to(\"cuda\")\n","            labels = batch['label'].to(\"cuda\")\n","\n","            optimizer.zero_grad()\n","            cls_output = shared_bert(input_ids, attention_mask)\n","            logits = model(cls_output)\n","            loss = F.cross_entropy(logits, labels)\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item()\n","\n","    torch.save(model.state_dict(), \"/content/drive/multi_augmentation_6.pt\")\n","\n","    # 평가\n","    model.eval()\n","    all_preds, all_labels = [], []\n","    with torch.no_grad():\n","        for batch in loader:\n","            input_ids = batch['input_ids'].to(\"cuda\")\n","            attention_mask = batch['attention_mask'].to(\"cuda\")\n","            labels = batch['label'].to(\"cpu\")\n","\n","            cls_output = shared_bert(input_ids, attention_mask)\n","            logits = model(cls_output).to(\"cpu\")\n","            preds = torch.argmax(logits, dim=1)\n","\n","            all_preds.extend(preds.numpy())\n","            all_labels.extend(labels.numpy())\n","\n","    print(\"\\n[다중 분류 평가 결과]\")\n","    print(classification_report(all_labels, all_preds, target_names=[\"일반대화\", \"협박\", \"갈취\", \"직장 내 괴롭힘\", \"기타 괴롭힘\"], digits=4))\n","\n","    return model"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"kau79Xvj1gwl","executionInfo":{"status":"error","timestamp":1746579978614,"user_tz":-540,"elapsed":67,"user":{"displayName":"권재현","userId":"02074875056020008335"}},"colab":{"base_uri":"https://localhost:8080/","height":211},"outputId":"31b9d052-0681-4eb2-88b8-60ea9e5996c2"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'nn' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-7fc12d94951e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mSharedBERT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"beomi/kcbert-base\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"]}],"source":["class SharedBERT(nn.Module):\n","    def __init__(self, model_name=\"beomi/kcbert-base\"):\n","        super().__init__()\n","        self.bert = BertModel.from_pretrained(model_name)\n","        for p in self.bert.parameters():\n","            p.requires_grad = False\n","\n","    def forward(self, input_ids, attention_mask):\n","        return self.bert(input_ids=input_ids, attention_mask=attention_mask).pooler_output\n","\n","# class SharedBERT(nn.Module):\n","#     def __init__(self, model_name=\"beomi/kcbert-base\"):\n","#         super().__init__()\n","#         self.bert = BertModel.from_pretrained(model_name)\n","#         for name, param in self.bert.named_parameters():\n","#             if 'encoder.layer.9' in name or \\\n","#                 'encoder.layer.10' in name or \\\n","#                     'encoder.layer.11' in name:\n","#                         param.requires_grad = True\n","#             else:\n","#                 param.requires_grad = False\n","\n","#     def forward(self, input_ids, attention_mask):\n","#         return self.bert(input_ids=input_ids, attention_mask=attention_mask).pooler_output"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":249,"referenced_widgets":["1c25e8947dd04907968a0d7dbbe2f7cb","5919f9ec4dd04fcbbe0aaaf54a1bfce8","0759f6996a734b99ad99142ca5c9b510","67a7d8fc6d004b6b98bd3b0cfbfbb7cd","0d54315daef0460291be45e5e6742c4b","f11d6fdb52914b698a4d1544d350800e","29cb2b3900864cd38278a7450497b43c","e9bd8f6ef50e4c8c88ba2035fb41cf84","ffcb726fa0844c7ab41a3be6cbc10ba2","4255551a89594ac0a923bc6101cfcfd5","491a6f16653d4f1c9d4c68133f04c8a2","5a50aacb8d9c45b582670ad28dc24452","12fb6e1964e64478a5dc9348e7ab19d5","fdd946315bd44a0481f24f3939965b97","5fd74dbda8ed4fea82ba54fe14b0d2b1","3696f8fd963c4b37930cb3c438cbd399","2dd6cd7374a24dcea4c527fa2189b29a","b94ddd0e6bb24e8bba49b1b4898586b0","e482257c6458446e9c3d03b929c3fdbe","b79b3926c2e84507a31587cc738a6ec8","2ba95212aed14922bc9c1cee9e10f269","85406b2a2c094e44b6e2ab5a95c9e681","4ce1c77b581c45e387899df06e927728","5f9efb9a2c944fd187a964d85dcabd9d","8b1faf40f7e8407bb0fa585692ba75b3","1c7851d62f3545c2b38c27a2edccc7e1","18b468614bf341799faf9db293f5c50a","32d22f27a4f440e296d59fb74c133b62","410941964e61463f820d9ed46320444b","0ccc2ff64bca4460a6ce3764c6855eb4","373a1125dd9341cf8063581b3fdc4bd9","7b1233c0ffca43be939f6ae3b60966bd","950da7f42a0b48dbb97fa9a571aa4013","1f395d0daad54af398b4af394c0e0098","08b8bf631de8422cbe7957c047b67240","10976c2d96b5470cb1d32954e2b07ec2","fa061ae117ee411cbb01561823b477df","97e53a67cd864735a094bf1a9a6b9232","38e4e7f6c43e4849930a16f9483eb62a","1eb49124661f44e58a7e53c75545f897","212c0cd6444146cf99bbd2b76d4e9914","e09013cb886f4dea8aae40aca1de648c","a04e7f95bdd544a0b744ed4ba0f1f6bf","6623c5f68c0a4d6faaa97015c87387c4"]},"id":"LxxW0PT6WgxQ","outputId":"5dbc411e-99a9-4672-8013-1ef4b3c28727"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c25e8947dd04907968a0d7dbbe2f7cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/250k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a50aacb8d9c45b582670ad28dc24452"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/619 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ce1c77b581c45e387899df06e927728"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f395d0daad54af398b4af394c0e0098"}},"metadata":{}}],"source":["# 토크나이저와 공유 BERT 로드\n","tokenizer = BertTokenizer.from_pretrained(\"beomi/kcbert-base\")\n","\n","shared_bert = SharedBERT().to(\"cuda\")\n","\n","# CSV 불러오기 및 라벨 처리\n","csv_path_ = '/content/drive/MyDrive/DLthon/merged_dataset_4.csv'\n","df_ = pd.read_csv(csv_path_)\n","\n","label_map = {\n","    '일반대화': 0,\n","    '협박 대화': 1,\n","    '갈취 대화': 2,\n","    '직장 내 괴롭힘 대화': 3,\n","    '기타 괴롭힘 대화': 4\n","}\n","df_['label'] = df_['class'].map(label_map)\n","df_.rename(columns={'class': 'original_label', 'conversation': 'text'}, inplace=True)\n","\n","# 학습 및 평가\n","trained_model = train_and_evaluate(df_, tokenizer, shared_bert)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZhkW5xh2EoCI"},"outputs":[],"source":["# Tapt 시도\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from sklearn.metrics import classification_report\n","import pandas as pd\n","\n","class MultiClassificationDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_length=128):\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","        # 일반대화 1000개 + 괴롭힘 전체 구성\n","        df_0 = dataframe[dataframe['label'] == 0].sample(n=1500, random_state=42)\n","        df_1to4 = dataframe[dataframe['label'].isin([1, 2, 3, 4])]\n","        balanced_df = pd.concat([df_0, df_1to4], ignore_index=True)\n","\n","        self.selected_texts = balanced_df['text'].tolist()\n","        self.selected_labels = balanced_df['label'].tolist()\n","\n","    def __len__(self):\n","        return len(self.selected_texts)\n","\n","    def __getitem__(self, idx):\n","        encoding = self.tokenizer(\n","            self.selected_texts[idx],\n","            truncation=True,\n","            padding='max_length',\n","            max_length=self.max_length,\n","            return_tensors='pt'\n","        )\n","        item = {key: val.squeeze(0) for key, val in encoding.items()}\n","        item['label'] = torch.tensor(self.selected_labels[idx], dtype=torch.long)\n","        return item\n","\n","class MultiClassifier(nn.Module):\n","    def __init__(self, hidden_size=768, num_classes=5):\n","        super().__init__()\n","        self.classifier = nn.Sequential(\n","            nn.Linear(hidden_size, 512),\n","            nn.ReLU(),\n","            nn.BatchNorm1d(512),\n","            nn.Linear(512, 256),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(256, num_classes)\n","        )\n","\n","    def forward(self, cls_output):\n","        return self.classifier(cls_output)\n","\n","def focal_loss(logits, targets, gamma=2.0, alpha=1.0):\n","    ce_loss = F.cross_entropy(logits, targets, reduction='none')\n","    pt = torch.exp(-ce_loss)\n","    focal = alpha * ((1 - pt) ** gamma) * ce_loss\n","    return focal.mean()\n","\n","# 학습 및 평가 코드\n","def train_and_evaluate(dataframe, tokenizer, shared_bert):\n","    from copy import deepcopy\n","\n","    dataset = MultiClassificationDataset(dataframe, tokenizer)\n","    loader = DataLoader(dataset, batch_size=32, shuffle=True)\n","\n","    model = MultiClassifier().to(\"cuda\")\n","    optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n","\n","    best_loss = float('inf')\n","    best_model_state = deepcopy(model.state_dict())\n","    patience = 4\n","    patience_counter = 0\n","\n","    for epoch in range(30):\n","        model.train()\n","        total_loss = 0\n","\n","    for batch in loader:\n","        input_ids = batch['input_ids'].to(\"cuda\")\n","        attention_mask = batch['attention_mask'].to(\"cuda\")\n","        labels = batch['label'].to(\"cuda\")\n","\n","        optimizer.zero_grad()\n","        output = shared_bert(input_ids=input_ids, attention_mask=attention_mask)\n","        cls_output = output.last_hidden_state[:, 0, :]  # [CLS] 벡터 추출\n","        logits = model(cls_output)\n","\n","        # focal loss for label==4 (기타 괴롭힘), cross-entropy for others\n","        if (labels == 4).any():\n","            focal_mask = labels == 4\n","            ce_mask = ~focal_mask\n","\n","            focal_loss_val = (\n","                focal_loss(logits[focal_mask], labels[focal_mask])\n","                if focal_mask.sum() > 0 else 0\n","            )\n","            ce_loss_val = (\n","                F.cross_entropy(logits[ce_mask], labels[ce_mask])\n","                if ce_mask.sum() > 0 else 0\n","            )\n","            loss = focal_loss_val + ce_loss_val\n","        else:\n","            loss = F.cross_entropy(logits, labels)\n","\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","\n","    # 최적 모델 저장\n","    if best_model_state is not None:\n","        model.load_state_dict(best_model_state)\n","    else:\n","        print(\"Warning: No best model was saved. Using the last trained model.\")\n","\n","    torch.save(model.state_dict(), \"/content/drive/MyDrive/DLthon/tapt_multi_1.pt\")\n","\n","    # 평가\n","    model.eval()\n","    all_preds, all_labels = [], []\n","    with torch.no_grad():\n","        for batch in loader:\n","            input_ids = batch['input_ids'].to(\"cuda\")\n","            attention_mask = batch['attention_mask'].to(\"cuda\")\n","            labels = batch['label'].to(\"cpu\")\n","\n","            cls_output = shared_bert(input_ids, attention_mask)\n","            logits = model(cls_output).to(\"cpu\")\n","            preds = torch.argmax(logits, dim=1)\n","\n","            all_preds.extend(preds.numpy())\n","            all_labels.extend(labels.numpy())\n","\n","    print(\"\\n[다중 분류 평가 결과]\")\n","    print(classification_report(\n","        all_labels,\n","        all_preds,\n","        target_names=[\"일반대화\", \"협박\", \"갈취\", \"직장 내 괴롭힘\", \"기타 괴롭힘\"],\n","        digits=4\n","    ))\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gezC_sFwIdtN"},"outputs":[],"source":["class SharedBERT(nn.Module):\n","    def __init__(self, model_name=\"beomi/kcbert-base\"):\n","        super().__init__()\n","        self.bert = BertModel.from_pretrained(model_name)\n","        for p in self.bert.parameters():\n","            p.requires_grad = False\n","\n","    def forward(self, input_ids, attention_mask):\n","        return self.bert(input_ids=input_ids, attention_mask=attention_mask).pooler_output"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":107436,"status":"error","timestamp":1746510814364,"user":{"displayName":"권재현","userId":"02074875056020008335"},"user_tz":-540},"id":"a16MhH0-FISK","outputId":"8cc8cfe1-dceb-4e21-8886-ab8743deb48c"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertModel were not initialized from the model checkpoint at /content/drive/MyDrive/DLthon/tapt_kcbert and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"ename":"TypeError","evalue":"linear(): argument 'input' (position 1) must be Tensor, not BaseModelOutputWithPoolingAndCrossAttentions","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-d1223d6d32ae>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# 학습 및 평가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared_bert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-20-02559838b63b>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(dataframe, tokenizer, shared_bert)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mcls_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshared_bert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-02559838b63b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, cls_output)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfocal_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not BaseModelOutputWithPoolingAndCrossAttentions"]}],"source":["# 토크나이저와 공유 BERT 로드\n","tokenizer = BertTokenizer.from_pretrained(\"beomi/kcbert-base\")\n","\n","shared_bert = BertModel.from_pretrained(\"/content/drive/MyDrive/DLthon/tapt_kcbert\").to('cuda')\n","\n","# CSV 불러오기 및 라벨 처리\n","csv_path_ = '/content/drive/MyDrive/DLthon/merged_dataset_2.csv'\n","df_ = pd.read_csv(csv_path_)\n","\n","label_map = {\n","    '일반대화': 0,\n","    '협박 대화': 1,\n","    '갈취 대화': 2,\n","    '직장 내 괴롭힘 대화': 3,\n","    '기타 괴롭힘 대화': 4\n","}\n","df_['label'] = df_['class'].map(label_map)\n","df_.rename(columns={'class': 'original_label', 'conversation': 'text'}, inplace=True)\n","\n","# 학습 및 평가\n","trained_model = train_and_evaluate(df_, tokenizer, shared_bert)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-hcmYUpiGPQm"},"outputs":[],"source":["# Focal Loss 시도\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizer, BertModel\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from sklearn.metrics import classification_report\n","import pandas as pd\n","from copy import deepcopy\n","\n","# focal loss 함수\n","def focal_loss(logits, targets, gamma=2.0, alpha=1.0):\n","    ce_loss = F.cross_entropy(logits, targets, reduction='none')\n","    pt = torch.exp(-ce_loss)\n","    focal = alpha * ((1 - pt) ** gamma) * ce_loss\n","    return focal.mean()\n","\n","# 데이터셋 클래스\n","class MultiClassificationDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_length=64):\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","        df_0 = dataframe[dataframe['label'] == 0].sample(n=1500, random_state=42)\n","        df_1to4 = dataframe[dataframe['label'].isin([1, 2, 3, 4])]\n","        balanced_df = pd.concat([df_0, df_1to4], ignore_index=True)\n","\n","        self.selected_texts = balanced_df['text'].tolist()\n","        self.selected_labels = balanced_df['label'].tolist()\n","\n","    def __len__(self):\n","        return len(self.selected_texts)\n","\n","    def __getitem__(self, idx):\n","        encoding = self.tokenizer(\n","            self.selected_texts[idx],\n","            truncation=True,\n","            padding='max_length',\n","            max_length=self.max_length,\n","            return_tensors='pt'\n","        )\n","        item = {key: val.squeeze(0) for key, val in encoding.items()}\n","        item['label'] = torch.tensor(self.selected_labels[idx], dtype=torch.long)\n","        return item\n","\n","# 분류기\n","class MultiClassifier(nn.Module):\n","    def __init__(self, hidden_size=768, num_classes=5):\n","        super().__init__()\n","        self.classifier = nn.Sequential(\n","            nn.Linear(hidden_size, 512),\n","            nn.ReLU(),\n","            nn.BatchNorm1d(512),\n","            nn.Linear(512, 256),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(256, num_classes)\n","        )\n","\n","    def forward(self, cls_output):\n","        return self.classifier(cls_output)\n","\n","# 학습 및 평가 함수\n","def train_and_evaluate(dataframe, tokenizer, shared_bert):\n","    dataset = MultiClassificationDataset(dataframe, tokenizer)\n","    loader = DataLoader(dataset, batch_size=32, shuffle=True)\n","\n","    model = MultiClassifier().to(\"cuda\")\n","    optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n","\n","    best_loss = float('inf')\n","    best_model_state = deepcopy(model.state_dict())\n","    patience = 4\n","    patience_counter = 0\n","\n","    for epoch in range(30):\n","        model.train()\n","        total_loss = 0\n","\n","        for batch in loader:\n","            input_ids = batch['input_ids'].to(\"cuda\")\n","            attention_mask = batch['attention_mask'].to(\"cuda\")\n","            labels = batch['label'].to(\"cuda\")\n","\n","            optimizer.zero_grad()\n","            output = shared_bert(input_ids=input_ids, attention_mask=attention_mask)\n","            cls_output = output.last_hidden_state[:, 0, :]  # [CLS] 벡터\n","            logits = model(cls_output)\n","\n","            if (labels == 4).any():\n","                focal_mask = labels == 4\n","                ce_mask = ~focal_mask\n","\n","                focal_loss_val = (\n","                    focal_loss(logits[focal_mask], labels[focal_mask])\n","                    if focal_mask.sum() > 0 else 0\n","                )\n","                ce_loss_val = (\n","                    F.cross_entropy(logits[ce_mask], labels[ce_mask])\n","                    if ce_mask.sum() > 0 else 0\n","                )\n","                loss = focal_loss_val + ce_loss_val\n","            else:\n","                loss = F.cross_entropy(logits, labels)\n","\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item()\n","\n","        avg_loss = total_loss / len(loader)\n","        print(f\"[Epoch {epoch+1}] Loss: {avg_loss:.4f}\")\n","\n","        if avg_loss < best_loss - 1e-4:\n","            best_loss = avg_loss\n","            best_model_state = deepcopy(model.state_dict())\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","            print(f\"  ↳ No improvement. Patience: {patience_counter}/{patience}\")\n","            if patience_counter >= patience:\n","                print(\"  ↳ Early stopping triggered.\")\n","                break\n","\n","    if best_model_state is not None:\n","        model.load_state_dict(best_model_state)\n","    else:\n","        print(\"Warning: Best model was not saved. Using last model state.\")\n","\n","    torch.save(model.state_dict(), \"/content/drive/MyDrive/DLthon/tapt_multi_2.pt\")\n","\n","    # 평가\n","    model.eval()\n","    all_preds, all_labels = [], []\n","    with torch.no_grad():\n","        for batch in loader:\n","            input_ids = batch['input_ids'].to(\"cuda\")\n","            attention_mask = batch['attention_mask'].to(\"cuda\")\n","            labels = batch['label'].to(\"cpu\")\n","\n","            output = shared_bert(input_ids=input_ids, attention_mask=attention_mask)\n","            cls_output = output.last_hidden_state[:, 0, :]\n","            logits = model(cls_output).to(\"cpu\")\n","            preds = torch.argmax(logits, dim=1)\n","\n","            all_preds.extend(preds.numpy())\n","            all_labels.extend(labels.numpy())\n","\n","    print(\"\\n[다중 분류 평가 결과]\")\n","    print(classification_report(\n","        all_labels,\n","        all_preds,\n","        target_names=[\"일반대화\", \"협박\", \"갈취\", \"직장 내 괴롭힘\", \"기타 괴롭힘\"],\n","        digits=4\n","    ))\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":929},"executionInfo":{"elapsed":452747,"status":"error","timestamp":1746517763883,"user":{"displayName":"권재현","userId":"02074875056020008335"},"user_tz":-540},"id":"j6S_-2bcKUcT","outputId":"56457f48-40b3-4f8a-ba3e-39159cc8079c"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertModel were not initialized from the model checkpoint at /content/drive/MyDrive/DLthon/tapt_kcbert and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["[Epoch 1] Loss: 1.3284\n","[Epoch 2] Loss: 0.9535\n","[Epoch 3] Loss: 0.6864\n","[Epoch 4] Loss: 0.5127\n","[Epoch 5] Loss: 0.3764\n","[Epoch 6] Loss: 0.2911\n","[Epoch 7] Loss: 0.2285\n","[Epoch 8] Loss: 0.1824\n","[Epoch 9] Loss: 0.1483\n","[Epoch 10] Loss: 0.1177\n","[Epoch 11] Loss: 0.1000\n","[Epoch 12] Loss: 0.0845\n","[Epoch 13] Loss: 0.0659\n","[Epoch 14] Loss: 0.0602\n","[Epoch 15] Loss: 0.0519\n","[Epoch 16] Loss: 0.0433\n","[Epoch 17] Loss: 0.0405\n","[Epoch 18] Loss: 0.0343\n","[Epoch 19] Loss: 0.0324\n","[Epoch 20] Loss: 0.0280\n","[Epoch 21] Loss: 0.0241\n","[Epoch 22] Loss: 0.0220\n","[Epoch 23] Loss: 0.0196\n","[Epoch 24] Loss: 0.0174\n","[Epoch 25] Loss: 0.0177\n","  ↳ No improvement. Patience: 1/4\n","[Epoch 26] Loss: 0.0151\n","[Epoch 27] Loss: 0.0143\n","[Epoch 28] Loss: 0.0131\n","[Epoch 29] Loss: 0.0121\n","[Epoch 30] Loss: 0.0103\n","\n","[다중 분류 평가 결과]\n"]},{"ename":"ValueError","evalue":"Number of classes, 1, does not match size of target_names, 5. Try specifying the labels parameter","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-6dd6237f19b5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdf_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'original_label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'conversation'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'text'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared_bert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-37-6becbadb183b>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(dataframe, tokenizer, shared_bert)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n[다중 분류 평가 결과]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     print(classification_report(\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2691\u001b[0m             )\n\u001b[1;32m   2692\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2693\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2694\u001b[0m                 \u001b[0;34m\"Number of classes, {0}, does not match size of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m                 \u001b[0;34m\"target_names, {1}. Try specifying the labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Number of classes, 1, does not match size of target_names, 5. Try specifying the labels parameter"]}],"source":["tokenizer = BertTokenizer.from_pretrained(\"/content/drive/MyDrive/DLthon/tapt_kcbert\")\n","shared_bert = BertModel.from_pretrained(\"/content/drive/MyDrive/DLthon/tapt_kcbert\").to('cuda')\n","\n","csv_path_ = '/content/drive/MyDrive/DLthon/merged_dataset_4.csv'\n","df_ = pd.read_csv(csv_path_)\n","\n","label_map = {\n","    '일반대화': 0,\n","    '협박 대화': 1,\n","    '갈취 대화': 2,\n","    '직장 내 괴롭힘 대화': 3,\n","    '기타 괴롭힘 대화': 4\n","}\n","df_['label'] = df_['class'].map(label_map)\n","df_.rename(columns={'class': 'original_label', 'conversation': 'text'}, inplace=True)\n","\n","train_and_evaluate(df_, tokenizer, shared_bert)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tKVfxLmNhr1H"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[{"file_id":"1aW7L8jSV0ynXX89wLKEwCf94nzCF8IPd","timestamp":1746579829050}],"authorship_tag":"ABX9TyNkUKmpn1/tV6sx+eVIxaDa"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"05419867b0144b248f41a87e87fb5784":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"173b5f13a2364c6281e6759bec25c603":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1828e7a57bf44835a850ebf2fe7117bb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e44693b5e3b453a9f53f4fe1bc7bc01":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ecec955dbf04f748cad137bd04bb6d2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"296babf6668349b3b5068dd276775973":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3211ad0b8ca84cc08764eece9771cc41":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34f51280f2f24292a1ad790e009cc8e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b307d8865e44523b7d712411a14e815":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41592c67b28340dfbe4a55c0c55e510b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"45dc06139bc449a5947a20ade7d60a35":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"464154207f904b02a917105f07303101":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"497420167f6d4692ba5ebfb1d524ee25":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7aa763b733c3466bb9b832b3f8f146eb","placeholder":"​","style":"IPY_MODEL_517ab2449e2e432fb101a8612a00c7a0","value":"tokenizer_config.json: 100%"}},"4c0c3da9dd1141b88a2049b6a033e4c5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bf8288481891438eaf38cf5597a6b77f","IPY_MODEL_c226ef96648449a7b5d284802725486f","IPY_MODEL_79eedd85521247db860dba8bea6377a1"],"layout":"IPY_MODEL_34f51280f2f24292a1ad790e009cc8e7"}},"4d6a039c545e44558445f71e4339e875":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_694a0f8a6e814d43be4ae889fdc85d7c","IPY_MODEL_72891edb5a054d45a82141fce11b8c65","IPY_MODEL_54d692adf84346a1a5863167d82cb010"],"layout":"IPY_MODEL_552e8c9d0fec497387012ee2850ee061"}},"517ab2449e2e432fb101a8612a00c7a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54d692adf84346a1a5863167d82cb010":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3211ad0b8ca84cc08764eece9771cc41","placeholder":"​","style":"IPY_MODEL_296babf6668349b3b5068dd276775973","value":" 619/619 [00:00&lt;00:00, 78.9kB/s]"}},"552e8c9d0fec497387012ee2850ee061":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5de847639cdd4ae7b361c4b3ab073ce7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1828e7a57bf44835a850ebf2fe7117bb","max":249928,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b5ce87fdcc4b407191dc77b3f4104c5f","value":249928}},"5e6e1bd4fa284c659be9233c98c91faa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65ee54b369184f36a2380c603ee35f52":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9f9f8aa278cf45879a618749794a5467","IPY_MODEL_5de847639cdd4ae7b361c4b3ab073ce7","IPY_MODEL_e2bcda98bb784ae28601f1018bd920d3"],"layout":"IPY_MODEL_5e6e1bd4fa284c659be9233c98c91faa"}},"68fe0ff4692346bd911d7cfbc5dafc7f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"694a0f8a6e814d43be4ae889fdc85d7c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9a8103a555742b3a4577ccd231c92df","placeholder":"​","style":"IPY_MODEL_971fc55f0eae45e39a974b9c8cadf986","value":"config.json: 100%"}},"6c3c7c706bef4bdbb3863e55be8548e0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d288cd22c094ad9b11a8d6fcd645107":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d9102f641464f71a740cfbe0cfc410b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6fd7613618b54891b26edfa003c0c7f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"72891edb5a054d45a82141fce11b8c65":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_173b5f13a2364c6281e6759bec25c603","max":619,"min":0,"orientation":"horizontal","style":"IPY_MODEL_68fe0ff4692346bd911d7cfbc5dafc7f","value":619}},"79eedd85521247db860dba8bea6377a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05419867b0144b248f41a87e87fb5784","placeholder":"​","style":"IPY_MODEL_464154207f904b02a917105f07303101","value":" 438M/438M [00:05&lt;00:00, 87.1MB/s]"}},"7aa763b733c3466bb9b832b3f8f146eb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d65395de6af46e5a9b7d3765e0e91e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_497420167f6d4692ba5ebfb1d524ee25","IPY_MODEL_a26d0e5adf484a3ea35e3c28962927eb","IPY_MODEL_d40a39d1c6f54605bbb7f87f3ba065df"],"layout":"IPY_MODEL_a5bd63d2f10f474f93d865ff21f504fa"}},"971fc55f0eae45e39a974b9c8cadf986":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f9f8aa278cf45879a618749794a5467":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ecec955dbf04f748cad137bd04bb6d2","placeholder":"​","style":"IPY_MODEL_6d9102f641464f71a740cfbe0cfc410b","value":"vocab.txt: 100%"}},"a26d0e5adf484a3ea35e3c28962927eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b307d8865e44523b7d712411a14e815","max":49,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6fd7613618b54891b26edfa003c0c7f0","value":49}},"a2a7eb3e33b54187b005f56627b3da9e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5bd63d2f10f474f93d865ff21f504fa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5ce87fdcc4b407191dc77b3f4104c5f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b7c3cd1bc81946e4bbf32117ed1d9f33":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf8288481891438eaf38cf5597a6b77f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c3c7c706bef4bdbb3863e55be8548e0","placeholder":"​","style":"IPY_MODEL_41592c67b28340dfbe4a55c0c55e510b","value":"model.safetensors: 100%"}},"c226ef96648449a7b5d284802725486f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_45dc06139bc449a5947a20ade7d60a35","max":438192852,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f4fd15a00fef4010b031f41f24e822a4","value":438192852}},"d40a39d1c6f54605bbb7f87f3ba065df":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7c3cd1bc81946e4bbf32117ed1d9f33","placeholder":"​","style":"IPY_MODEL_1e44693b5e3b453a9f53f4fe1bc7bc01","value":" 49.0/49.0 [00:00&lt;00:00, 6.29kB/s]"}},"e2bcda98bb784ae28601f1018bd920d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2a7eb3e33b54187b005f56627b3da9e","placeholder":"​","style":"IPY_MODEL_6d288cd22c094ad9b11a8d6fcd645107","value":" 250k/250k [00:00&lt;00:00, 3.38MB/s]"}},"f4fd15a00fef4010b031f41f24e822a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f9a8103a555742b3a4577ccd231c92df":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c25e8947dd04907968a0d7dbbe2f7cb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5919f9ec4dd04fcbbe0aaaf54a1bfce8","IPY_MODEL_0759f6996a734b99ad99142ca5c9b510","IPY_MODEL_67a7d8fc6d004b6b98bd3b0cfbfbb7cd"],"layout":"IPY_MODEL_0d54315daef0460291be45e5e6742c4b"}},"5919f9ec4dd04fcbbe0aaaf54a1bfce8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f11d6fdb52914b698a4d1544d350800e","placeholder":"​","style":"IPY_MODEL_29cb2b3900864cd38278a7450497b43c","value":"tokenizer_config.json: 100%"}},"0759f6996a734b99ad99142ca5c9b510":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9bd8f6ef50e4c8c88ba2035fb41cf84","max":49,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ffcb726fa0844c7ab41a3be6cbc10ba2","value":49}},"67a7d8fc6d004b6b98bd3b0cfbfbb7cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4255551a89594ac0a923bc6101cfcfd5","placeholder":"​","style":"IPY_MODEL_491a6f16653d4f1c9d4c68133f04c8a2","value":" 49.0/49.0 [00:00&lt;00:00, 5.74kB/s]"}},"0d54315daef0460291be45e5e6742c4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f11d6fdb52914b698a4d1544d350800e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29cb2b3900864cd38278a7450497b43c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9bd8f6ef50e4c8c88ba2035fb41cf84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffcb726fa0844c7ab41a3be6cbc10ba2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4255551a89594ac0a923bc6101cfcfd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"491a6f16653d4f1c9d4c68133f04c8a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a50aacb8d9c45b582670ad28dc24452":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_12fb6e1964e64478a5dc9348e7ab19d5","IPY_MODEL_fdd946315bd44a0481f24f3939965b97","IPY_MODEL_5fd74dbda8ed4fea82ba54fe14b0d2b1"],"layout":"IPY_MODEL_3696f8fd963c4b37930cb3c438cbd399"}},"12fb6e1964e64478a5dc9348e7ab19d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2dd6cd7374a24dcea4c527fa2189b29a","placeholder":"​","style":"IPY_MODEL_b94ddd0e6bb24e8bba49b1b4898586b0","value":"vocab.txt: 100%"}},"fdd946315bd44a0481f24f3939965b97":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e482257c6458446e9c3d03b929c3fdbe","max":249928,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b79b3926c2e84507a31587cc738a6ec8","value":249928}},"5fd74dbda8ed4fea82ba54fe14b0d2b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ba95212aed14922bc9c1cee9e10f269","placeholder":"​","style":"IPY_MODEL_85406b2a2c094e44b6e2ab5a95c9e681","value":" 250k/250k [00:00&lt;00:00, 6.34MB/s]"}},"3696f8fd963c4b37930cb3c438cbd399":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2dd6cd7374a24dcea4c527fa2189b29a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b94ddd0e6bb24e8bba49b1b4898586b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e482257c6458446e9c3d03b929c3fdbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b79b3926c2e84507a31587cc738a6ec8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ba95212aed14922bc9c1cee9e10f269":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85406b2a2c094e44b6e2ab5a95c9e681":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ce1c77b581c45e387899df06e927728":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5f9efb9a2c944fd187a964d85dcabd9d","IPY_MODEL_8b1faf40f7e8407bb0fa585692ba75b3","IPY_MODEL_1c7851d62f3545c2b38c27a2edccc7e1"],"layout":"IPY_MODEL_18b468614bf341799faf9db293f5c50a"}},"5f9efb9a2c944fd187a964d85dcabd9d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32d22f27a4f440e296d59fb74c133b62","placeholder":"​","style":"IPY_MODEL_410941964e61463f820d9ed46320444b","value":"config.json: 100%"}},"8b1faf40f7e8407bb0fa585692ba75b3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ccc2ff64bca4460a6ce3764c6855eb4","max":619,"min":0,"orientation":"horizontal","style":"IPY_MODEL_373a1125dd9341cf8063581b3fdc4bd9","value":619}},"1c7851d62f3545c2b38c27a2edccc7e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b1233c0ffca43be939f6ae3b60966bd","placeholder":"​","style":"IPY_MODEL_950da7f42a0b48dbb97fa9a571aa4013","value":" 619/619 [00:00&lt;00:00, 80.3kB/s]"}},"18b468614bf341799faf9db293f5c50a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32d22f27a4f440e296d59fb74c133b62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"410941964e61463f820d9ed46320444b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ccc2ff64bca4460a6ce3764c6855eb4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"373a1125dd9341cf8063581b3fdc4bd9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7b1233c0ffca43be939f6ae3b60966bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"950da7f42a0b48dbb97fa9a571aa4013":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f395d0daad54af398b4af394c0e0098":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_08b8bf631de8422cbe7957c047b67240","IPY_MODEL_10976c2d96b5470cb1d32954e2b07ec2","IPY_MODEL_fa061ae117ee411cbb01561823b477df"],"layout":"IPY_MODEL_97e53a67cd864735a094bf1a9a6b9232"}},"08b8bf631de8422cbe7957c047b67240":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_38e4e7f6c43e4849930a16f9483eb62a","placeholder":"​","style":"IPY_MODEL_1eb49124661f44e58a7e53c75545f897","value":"model.safetensors: 100%"}},"10976c2d96b5470cb1d32954e2b07ec2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_212c0cd6444146cf99bbd2b76d4e9914","max":438192852,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e09013cb886f4dea8aae40aca1de648c","value":438192852}},"fa061ae117ee411cbb01561823b477df":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a04e7f95bdd544a0b744ed4ba0f1f6bf","placeholder":"​","style":"IPY_MODEL_6623c5f68c0a4d6faaa97015c87387c4","value":" 438M/438M [00:01&lt;00:00, 250MB/s]"}},"97e53a67cd864735a094bf1a9a6b9232":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38e4e7f6c43e4849930a16f9483eb62a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1eb49124661f44e58a7e53c75545f897":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"212c0cd6444146cf99bbd2b76d4e9914":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e09013cb886f4dea8aae40aca1de648c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a04e7f95bdd544a0b744ed4ba0f1f6bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6623c5f68c0a4d6faaa97015c87387c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}